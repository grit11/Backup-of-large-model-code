#迭代版本Version1:对多卡并行进行了优化，解决了启动模型时无法多卡运行的问题

1.根据模型参数大小租赁合适的服务器（询问ChatGpt具体的配置）
  根据模型的参数大小租赁相关服务器，Qwen2.5-VL-72B-Instruct参数大概需要140G的数据盘，显存200G左右，我配置的是4XL20(48G)的卡
2.创建新的环境激活并按照相关依赖项
  参照requirements.txt文档
3.运行模型下载脚本
  download.py
4.运行模型启动脚本（可实现多卡并行）
  run_vilm.sh
5.运行测试脚本验证模型性能
  test.py
